---
title: " ML EXPLORATORY DATA ANALYSIS EDA"
output: html_notebook
---



TO DO/ADD:
(https://towardsdatascience.com/exploratory-data-analysis-in-r-for-beginners-fe031add7072
INCLUDE GGPLOT 2

AND INCLUDE ESQUISSE
https://towardsdatascience.com/top-r-libraries-for-data-science-9b24f658e243)

First load libraries and preprocess the data
```{r}

library(tidyverse)
library(DataExplorer)
library(GGally)
library(reshape)

# Importing the dataset
dataset = read.csv("C:/Users/trasa/Desktop/2020 2nd semester/Machine Learning/Contest/test.csv")

#Removing strings na with NA and later on 0
dataset[ dataset == "na" ] <- NA
dataset[is.na(dataset)] <- 0

#People who never saw ad in old campaign (kept as -1 --> changed to 0)
dataset$days_elapsed_old[dataset$days_elapsed_old<1] <- 0

#Factor like columns
dataset$job=as.numeric(as.factor(dataset$job))
dataset$marital=as.numeric(as.factor(dataset$marital))
dataset$education=as.numeric(as.factor(dataset$education))
dataset$device=as.numeric(as.factor(dataset$device))
dataset$outcome_old=as.numeric(as.factor(dataset$outcome_old))


# Encoding the target feature as factor
#dataset$y= factor(dataset$y, levels = c(0, 1))

# Splitting the dataset into the Training set and Test set
#install.packages('caTools')
library(caTools)
set.seed(123)
?split()
split = sample.split(dataset$y, SplitRatio =0.75)

training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)

# Feature Scaling
training_set[-17] = scale(training_set[-17])
test_set[-17] = scale(test_set[-17])

```

```{r}
web<- dataset
glimpse(web)
#To go with glimpse(), DataExplorer itself has got a function called introduce()
introduce(web)

#The same introduce() could also be plotted in a pretty graph.
plot_intro(web,  ggtheme = theme_dark(),
             title = "EDA with Data Explorer",
             )
```


EDA â€“ Missing
```{r}
plot_missing(web,  
             ggtheme = theme_dark(),
             title = " Features missing from the whole observations",
             )
```

EDA for Continuous
```{r}
##for univariate
?DataExplorer()

DataExplorer::plot_histogram(web,  
             ggtheme = theme_dark(),
             title = " Histogram of continuous features",
             )

plot_density(web,  
             ggtheme = theme_dark(),
             title = " Density of continuous features",
             )  # age, time_spent, X4 are right skewed
#outcome old hase a mode which is na-> remove this category? or remove this variable??

plot_bar(web,  
             ggtheme = theme_dark(),
             title = " Density of continuous features",
             )  ##VISUALIZE DATA WHEN X2=1 AND =2 (subsetting)

                    
                    a<- filter(web, web$X1==0)
                    b<- filter(web, web$X1==1)
                    plot_bar(a)
                    plot_bar(b)
                    plot_density(a,
                                 title = " a")
                    plot_density(b,
                                 title = " b") # => we see that when X1=2 there is more noise and                                                      variation in y output

##for bivariate
  plot_boxplot(web, by= 'day' , ncol = 1,   
             ggtheme = theme_dark(),
             title = " Boxplot of continuous features by day",
             )
  ?plot_boxplot()

##autocorr plot
plot_correlation(web, cor_args = list( 'use' = 'complete.obs'),  
             ggtheme = theme_dark(),
             title = " Autocorr Plot",
             )

##continurous correlation plot
plot_correlation(web, type = 'c',cor_args = list( 'use' = 'complete.obs'),  
             ggtheme = theme_dark(),
             title = " Continuous corr Plot",
             )   #marital and age negative correlation/ edu and job pos corr/ pos corr outcomr old and banner old, days old and banners old, y and outcome old

```


EDA for Categorical
```{r}
plot_bar(a, maxcat = 390, parallel = FALSE,  
             ggtheme = theme_dark(),
             title = " Categorical Features Plot",
             )
```


Correction
```{r}
web<- dataset

web$age<-sqrt(web$age)
web$time_spent<-sqrt(sqrt(web$time_spent))
 # age, time_spent are right skewed
plot_density(web,  
             ggtheme = theme_dark(),
             title = " Density of continuous features",
             ) 
dataset<-web

```


PCA ANALYSIS
You need to consider only numerical data, so leaving out: job, marital, education, device, outcome old

```{r}

library(devtools)
install_github("vqv/ggbiplot")
library(ggbiplot)

str(web)
web.pca <- prcomp(web, center = TRUE, scale. = TRUE)

summary(web.pca)

str(web.pca)

ggbiplot(web.pca)
ggbiplot(web.pca, labels=rownames(web)) #PCA 1,2 -> banner view old and day elapsed old (positive impact), banners views, education, age have also impact on PCA 1 and 2) 
ggbiplot(web.pca,ellipse=TRUE,choices=c(2,3),   labels=rownames(web)) #PCA 2,3 ->confirms last plot, with also marital impact
ggbiplot(web.pca,ellipse=TRUE,choices=c(3,4),   labels=rownames(web)) #PCA 3 and 4 -> time spent

#webs.country <- c(rep("Japan", 3), rep("US",4), rep("Europe", 7),rep("US",3), "Europe", rep("Japan", 3), rep("US",4), rep("Europe", 3), "US", rep("Europe", 3))
#ggbiplot(web.pca,ellipse=TRUE,  labels=rownames(web$age), groups = web.country)


```


Lasso & Ridge(to finish)
```{r}
library(tidyverse)
library(caret)
library(glmnet)

# Split the data into training and test set
set.seed(123) 
dat<-web
#  Extract  matrix  x  and  vector  y  from  data.frame  dat
x  <-  as.matrix(dat[,  -1])
y  <-  as.matrix(dat[,  1])
#  Compute  grid  of  values  for  lambda
grid  <-  10  ^  (seq(4,  -2,  length  =  61))



#  Fit  ridge  regression
fit.ridge  <-  glmnet(x,  y,  alpha  =  0,  lambda  =  grid,  standardize  =  TRUE)
plot(fit.ridge,  xvar  =  "lambda")
#  Perform  10-fold  cross-validation
cv.ridge  <-  cv.glmnet(x,  y,  alpha  =  0,  lambda  =  grid,  standardize  =  TRUE)
#  Plot  MSE  as  function  of  lambda
plot(cv.ridge)
#  Compute  the  optimal  lambda  using  the  one  standard  error  rule
opt_lambda  <-  cv.ridge$lambda.1se;  log(opt_lambda)
fit.lasso$
#  Fit  lasso  regression
fit.lasso  <-  glmnet(x,  y,  alpha  =  1,  lambda  =  grid,  standardize  =  TRUE)
plot(fit.lasso,  xvar  =  "lambda")
#  Perform  10-fold  cross-validation
cv.lasso  <-  cv.glmnet(x,  y,  alpha  =  1,  lambda  =  grid,  standardize  =  TRUE)
#  Plot  MSE  as  function  of  lambda
plot(cv.lasso)
#  Compute  the  optimal  lambda  using  the  one  standard 

beta=coef(fit.lasso)

tmp <- as.data.frame(as.matrix(beta))
tmp$coef <- row.names(tmp)
tmp <- reshape::melt(tmp, id = "coef")
tmp$variable <- as.numeric(gsub("s", "", tmp$variable))
tmp$lambda <- fit.lasso$lambda[tmp$variable+1] # extract the lambda values
tmp$norm <- apply(abs(beta[-1,]), 2, sum)[tmp$variable+1] # compute L1 norm



ggplot(tmp[tmp$coef != "(Intercept)",], aes(lambda, value, color = coef, linetype = coef)) + 
    geom_line() + 
    scale_x_log10() + 
    xlab("Lambda (log scale)") + 
    guides(color = guide_legend(title = ""), 
           linetype = guide_legend(title = "")) +
    theme_bw() + 
    theme(legend.key.width = unit(3,"lines"))

#keep device,marital,time spent, education,age, outcome old, months
```



EDA Report
```{r}
create_report(
  web,
  output_file = "EDA report.html",
  output_dir = getwd(),
  y = NULL,
  config = configure_report(),
  report_title = "Exploratory Data Analysis Report")
##getwd()
```


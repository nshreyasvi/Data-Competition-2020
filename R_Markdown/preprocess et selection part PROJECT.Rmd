---
title: "DATACOMP PRACTICALS"
author: "Trasatti Nelson"
date: "16/04/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r LOAD PREPROCESS}

train <- read.csv("train.csv")
dataset<- train

```

```{r }

 
library(funModeling) 
library(tidyverse) 
library(Hmisc)
library(mice)
  summary(train$device)
is.na(train) #check na->no
train[train=="na"] <- NA  #recod na as NA
is.na(train) #check na->YES
sum(is.na(train)) #->8911
Detect(train,n=5 )
table(Detect(train))
 md.pattern(train)
  
library(VIM)
mice_plot <- aggr(train, col=c('navyblue','yellow'),
                    numbers=TRUE, sortVars=TRUE,
                    labels=names(train), cex.axis=.7,
                    gap=3, ylab=c("Missing data","Pattern"))

train[train=="-1"] <- 0  #recod na as NA

imputed_Data <- mice(train,m=5,maxit=50, method =c('pmm','polyreg','polyreg','polyreg','polyreg','pmm','pmm','pmm','pmm','pmm','pmm','pmm','pmm','pmm','pmm','pmm', seed=500))
 sum(is.na(completeData)) #->8911
 train<-completeData

summary(train)

 summary(imputed_Data)
 
#check imputed values
 imputed_Data$imp$job
#get complete data ( 2nd out of 5)
 completeData <- complete(imputed_Data,2)
is.na(train)
```

```{r EDA}

train <- completeData
dataset<-train

dataset$job=as.integer(as.factor(dataset$job))
dataset$marital=as.integer(as.factor(dataset$marital))
dataset$education=as.integer(as.factor(dataset$education))
dataset$device=as.integer(as.factor(dataset$device))
dataset$outcome_old=as.integer(as.factor(dataset$outcome_old))
dataset[,5]=as.factor(dataset[,5])
dataset[,13]=as.factor(dataset[,13])
dataset[,14]=as.factor(dataset[,14])
dataset[,15]=as.factor(dataset[,15])
dataset[,17]=as.factor(dataset[,17])

# Splitting the dataset into the Training set and Test set
#install.packages('caTools')
library(caTools)
set.seed(123)
?split()
split = sample.split(dataset$y, SplitRatio =0.75)

training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)

# Feature Scaling
#training_set[-c(17,15,14,13,17,-2)] = scale(training_set[,-c(17,15,14,13,17,-2)])

web<- dataset
glimpse(web)
#To go with glimpse(), DataExplorer itself has got a function called introduce()
library(DataExplorer)

introduce(web)

#The same introduce() could also be plotted in a pretty graph.
plot_intro(web,  ggtheme = theme_dark(),
             title = "EDA with Data Explorer",
             )
plot_missing(web,  
             ggtheme = theme_dark(),
             title = " Features missing from the whole observations",
             )

DataExplorer::plot_histogram(web,  
             ggtheme = theme_dark(),
             title = " Histogram of continuous features",
             )

plot_density(web,  
             ggtheme = theme_dark(),
             title = " Density of continuous features",
             )  # age, time_spent, X4 are right skewed
#outcome old hase a mode which is na-> remove this category? or remove this variable??

plot_bar(web,  
             ggtheme = theme_dark(),
             title = " Density of continuous features",
             )  ##VISUALIZE DATA WHEN X2=1 AND =2 (subsetting)

                    library(reshape)

                    a<- filter(web, web$X1==1)
                    b<- filter(web, web$X1==2)
                    hist(a)
                    hist(b)
                   

##for bivariate
  plot_boxplot(web, by= 'day' , ncol = 1,   
             ggtheme = theme_dark(),
             title = " Boxplot of continuous features by day",
             )
  ?plot_boxplot()

##autocorr plot
plot_correlation(web, cor_args = list( 'use' = 'complete.obs'),  
             ggtheme = theme_dark(),
             title = " Autocorr Plot",
             )

##continurous correlation plot
plot_correlation(web, type = 'c',cor_args = list( 'use' = 'complete.obs'),  
             ggtheme = theme_dark(),
             title = " Continuous corr Plot",
             )   #marital and age negative correlation/ edu and job pos corr/ pos corr outcomr old and banner old, days old and banners old, y and outcome old
plot_bar(a, maxcat = 390, parallel = FALSE,  
             ggtheme = theme_dark(),
             title = " Categorical Features Plot",
             )

web$age<-sqrt(sqrt(web$age))
web$time_spent<-sqrt(sqrt(web$time_spent))
 # age, time_spent are right skewed
plot_density(web,  
             ggtheme = theme_dark(),
             title = " Density of continuous features",
             ) 

basic_eda <- function(data)
{
  glimpse(data)
  df_status(data)
  freq(data) 
  profiling_num(data)
  plot_num(data)
  describe(data)
}

basic_eda(web)


dataset<-web


```

Lasso & Ridge(to finish)
```{r}
library(tidyverse)
library(caret)
library(glmnet)

# Split the data into training and test set
set.seed(123) 
dat<-web
#  Extract  matrix  x  and  vector  y  from  data.frame  dat
x  <-  as.matrix(dat[,  -17])
y  <-  as.matrix(dat[,  17])
require(methods)


#  Compute  grid  of  values  for  lambda
grid  <-  10  ^  (seq(4,  -2,  length  =  61))



#  Fit  ridge  regression
fit.ridge  <-  glmnet(x,  y,  alpha  =  0,  lambda  =  grid,  standardize  =  TRUE)
plot(fit.ridge,  xvar  =  "lambda")
#  Perform  10-fold  cross-validation
predict(object = lm, newx =  as(x, "dgCMatrix"), type = "response")


#XXXXXXXXXXXXXX here the problem with cross valid.

cv.ridge  <-  cv.glmnet(x,  y,  alpha  =  0,  lambda  =  grid,  standardize  =  TRUE)
#  Plot  MSE  as  function  of  lambda
plot(cv.ridge)
#  Compute  the  optimal  lambda  using  the  one  standard  error  rule
opt_lambda  <-  cv.ridge$lambda.1se;  log(opt_lambda)
fit.lasso$
#  Fit  lasso  regression
fit.lasso  <-  glmnet(x,  y,  alpha  =  1,  lambda  =  grid,  standardize  =  TRUE)
plot(fit.lasso,  xvar  =  "lambda")
#  Perform  10-fold  cross-validation
cv.lasso  <-  cv.glmnet(x,  y,  alpha  =  1,  lambda  =  grid,  standardize  =  TRUE)
#  Plot  MSE  as  function  of  lambda
plot(cv.lasso)
#  Compute  the  optimal  lambda  using  the  one  standard 

beta=coef(fit.lasso)

tmp <- as.data.frame(as.matrix(beta))
tmp$coef <- row.names(tmp)
tmp <- reshape::melt(tmp, id = "coef")
tmp$variable <- as.numeric(gsub("s", "", tmp$variable))
tmp$lambda <- fit.lasso$lambda[tmp$variable+1] # extract the lambda values
tmp$norm <- apply(abs(beta[-1,]), 2, sum)[tmp$variable+1] # compute L1 norm



ggplot(tmp[tmp$coef != "(Intercept)",], aes(lambda, value, color = coef, linetype = coef)) + 
    geom_line() + 
    scale_x_log10() + 
    xlab("Lambda (log scale)") + 
    guides(color = guide_legend(title = ""), 
           linetype = guide_legend(title = "")) +
    theme_bw() + 
    theme(legend.key.width = unit(3,"lines"))

#keep device,marital,time spent, education,age, outcome old, months
```

```{r }



```
